# ğŸ§ Projet â€” SÃ©paration Voix / Instrumental 

Projet acadÃ©mique **CY Tech â€” Traitement du signal**  
DÃ©veloppÃ© en **Python (NumPy, SciPy, Librosa, Matplotlib, mir_eval)**

RÃ©alisÃ© par : Rayane Manseur Rayan Hussein Emine Ould Agatt Florian Vo Romain BowÃ© ClÃ©ment Rimbeuf Anthusan Srikaran

Lâ€™**objectif** du projet est de sÃ©parer un morceau audio en deux composantes :
la **voix** et lâ€™**instrumental**, en utilisant des mÃ©thodes classiques du traitement du signal :
**STFT, masques tempsâ€“frÃ©quence, filtrage frÃ©quentiel, HPSS, variation temporelle, reconstruction, et Ã©valuation quantitative (SDR, SIR, SAR).**

Ce pipeline complet permet dâ€™aller depuis les donnÃ©es brutes, jusquâ€™Ã  la reconstruction et lâ€™analyse comparative des mÃ©thodes.

---

## ğŸ¯ Objectifs du projet

Ce projet illustre plusieurs opÃ©rations de **traitement du signal audio** :

1. Comprendre et appliquer les bases du **traitement du signal audio**.
2. Manipuler la **DFT / FFT, STFT**, **masques frÃ©quences / temps**.
3. ImplÃ©menter plusieurs mÃ©thodes de **sÃ©paration de sources**.
4. GÃ©nÃ©rer un dataset contrÃ´lÃ© (mÃ©langes voix + instrumental).
5. Reconstruire des signaux via **ISTFT**.
6. Ã‰valuer les mÃ©thodes via les mÃ©triques standard (**SDR, SIR, SAR**).
7. Visualiser les masques et les rÃ©sultats


---
## ğŸ“ Structure du projet

```text
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mix.py                # GÃ©nÃ©ration automatique des mixes
â”‚   â”œâ”€â”€ separation.py         # ImplÃ©mentation des 4 mÃ©thodes de sÃ©paration
â”‚   â”œâ”€â”€ stft_utils.py         # Fonctions STFT / ISTFT / normalisation
â”‚   â”œâ”€â”€ metrics.py            # Calcul des mÃ©triques SDR / SIR / SAR
â”‚   â”œâ”€â”€ plots.py              # Affichage des masques et signaux
â”‚   â””â”€â”€ main.py               # Pipeline principal (lecture â†’ sÃ©paration â†’ save â†’ metrics)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Vocals/               # Pistes vocales de rÃ©fÃ©rence
â”‚   â”œâ”€â”€ Instrumentals/        # Pistes instrumentales de rÃ©fÃ©rence
â”‚   â””â”€â”€ Mixes/                # Mixes gÃ©nÃ©rÃ©s automatiquement
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ <nom_du_mix>/
    â”‚   â”œâ”€â”€ vocals_est.wav
    â”‚   â”œâ”€â”€ instru_est.wav
    â”‚   â”œâ”€â”€ mask_bande.png
    â”‚   â”œâ”€â”€ mask_hpss.png
    â”‚   â”œâ”€â”€ mask_variability.png
    â”‚   â””â”€â”€ mask_hybride.png
    â””â”€â”€ metrics_globales.csv

```

---

## ğŸ§° Outils requis sur chaque machine

- Python 3.x
- BibliothÃ¨ques Python :
    - `numpy`
    - `scipy`
    - `matplotlib`
    - `librosa`
    - `mir_eval`

Installation des dÃ©pendances (par exemple) :
```bash
pip install numpy scipy matplotlib librosa mir_eval
```
---

## ğŸš€ Pipeline complet
###1ï¸âƒ£ GÃ©nÃ©ration automatique des mixes (`mix.py`)

Ce script :

- charge la piste vocale et instrumentale
- convertit en mono si nÃ©cessaire
- normalise chaque signal
- applique un mix linÃ©aire :
      `mix = Î±Â·voix + Î²Â·instrumental`
- sauvegarde le mix dans `data/mix`

Pour lancer la gÃ©nÃ©ration de tous les mixes :
```bash
python src/mix.py
```

---

###2ï¸âƒ£ Analyse tempsâ€“frÃ©quence via STFT

Nous utilisons :

- `librosa.stft` pour obtenir le spectrogramme complexe
- module
  `S(f,t) = |S(f,t)| e^{iÏ•(f,t)}`

Toutes les mÃ©thodes de sÃ©paration travaillent sur le spectrogramme, jamais sur le signal temps direct.

---

###3ï¸âƒ£ MÃ©thodes de sÃ©paration (`separation.py`)

Nous avons implÃ©mentÃ© 4 mÃ©thodes :

- Filtre en bande (80â€“4000 Hz) : simple filtre frÃ©quentiel basÃ© sur la gamme vocale.

- HPSS (Harmonic / Percussive Source Separation) : sÃ©paration par filtres mÃ©dians :
        - composante harmonique â†’ voix
        - composante percussive â†’ instrumental

- Masque par variabilitÃ© temporelle : analyse des variations rapides du module du spectre.

- Masque hybride (mÃ©thode finale) : combinaison pondÃ©rÃ©e des 3 prÃ©cÃ©dentes. **Meilleure mÃ©thode selon notre Ã©tude.**

Chaque mÃ©thode gÃ©nÃ¨re :
- `vocals_est.wav`
- `instru_est.wav`

Ainsi que les masques (png), sauvegardÃ©s via `Vizualitation.py`.

---

###4ï¸âƒ£ Reconstruction temporelle (`src/other/IFFT.py`)

- ISTFT via librosa.istft
- Tests de cohÃ©rence sur signaux simples

Dans le pipeline rÃ©el, la reconstruction est dÃ©clenchÃ©e depuis `separation.py`.


---

###5ï¸âƒ£ Visualisation (`src/other/Vizualitation.py`)

GÃ©nÃ¨re automatiquement :

- spectrogrammes
- masques de sÃ©paration (voix/instru)
- courbes temporelles

---

###6ï¸âƒ£ Ã‰valuation SDR / SIR / SAR

Dans `separation.py` :

- compare chaque source estimÃ©e aux sources rÃ©elles
- utilise `mir_eval.separation.bss_eval_sources`
- gÃ©nÃ¨re un CSV global de rÃ©sultats :

```bash
results_metrics.csv
```
---

###ğŸ“Š RÃ©sultats (rÃ©sumÃ© du rapport)

- **Hybride** = meilleure mÃ©thode (SDR â‰ˆ 9 dB)

- **HPSS** = bon compromis

- **Filtre bande** = simple mais limitÃ©

- **VariabilitÃ©** = meilleur SIR mais dÃ©truit le signal â†’ mauvais SDR/SAR

---

##â–¶ï¸ ExÃ©cution du pipeline complet

```bash
python src/separation.py
```

Ce script :

- charge les mixes

- applique les 4 mÃ©thodes

- reconstruit les sources

- gÃ©nÃ¨re les masques + figures

- calcule les mÃ©triques
